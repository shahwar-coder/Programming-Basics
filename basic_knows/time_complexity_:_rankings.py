'''
â±ï¸ TIME COMPLEXITY RANKING (from best to worst)

1ï¸âƒ£ O(1) â€” Constant Time
   â†’ Execution time does NOT depend on input size.
   Example: accessing arr[0], checking x % 2, assigning a variable.

2ï¸âƒ£ O(log n) â€” Logarithmic Time
   â†’ Input reduces by half each step.
   Example: binary search, finding element in balanced BST.

3ï¸âƒ£ O(n) â€” Linear Time
   â†’ Time grows directly with input size.
   Example: single loop over list, sum(arr), count True values.

4ï¸âƒ£ O(n log n) â€” Linearithmic Time
   â†’ Common in efficient sorting algorithms.
   Example: merge sort, quicksort (average), heap sort.

5ï¸âƒ£ O(nÂ²) â€” Quadratic Time
   â†’ Nested loops over same list size.
   Example: bubble sort, comparing every pair of elements.

6ï¸âƒ£ O(nÂ³) â€” Cubic Time
   â†’ Triple nested loops.
   Example: some brute-force 3D matrix operations.

7ï¸âƒ£ O(2â¿) â€” Exponential Time
   â†’ Doubles with each additional element.
   Example: recursive subset generation, naive Fibonacci recursion.

8ï¸âƒ£ O(n!) â€” Factorial Time
   â†’ Permutations or brute-force over all arrangements.
   Example: generating all permutations of a string.

âœ… Summary (fast â†’ slow):
O(1)  <  O(log n)  <  O(n)  <  O(n log n)  <  O(nÂ²)  <  O(nÂ³)  <  O(2â¿)  <  O(n!)

ğŸ’¡ Rule of thumb:
- Aim for O(1) or O(n) in most coding problems.
- O(n log n) is usually acceptable for sorting or complex searches.
- Avoid O(nÂ²)+ unless input size is very small.
'''
